---
id: 3d6f66bc-b9f9-4102-8e65-9d4b7e802190
blueprint: article
title: 'Faster than Ollama: GPU Accelerated AI Voice Assistant on a Raspberry Pi'
description: 'Setting up a powerful, local AI voice assistant using the Sanctuary Systems Sentinel Core'
page_builder:
  -
    id: mdsl42zf
    lead_title: 'Faster than Ollama:'
    title: 'GPU Accelerated AI Voice Assistant on a Raspberry Pi'
    description: 'Setting up a powerful, local AI voice assistant using the Sanctuary Systems Sentinel Core'
    type: hero
    enabled: true
  -
    id: mdsm7oze
    youtube_video_url: 'https://www.youtube.com/embed/h1oaRtc9SEA?si=Ya_kqbqnTtAIOCkS'
    type: youtube_video
    enabled: true
  -
    id: mdsl5oc3
    content:
      -
        type: paragraph
        content:
          -
            type: text
            text: '"Please turn on the studio lights."'
      -
        type: paragraph
        content:
          -
            type: text
            text: '"The studio lights have been turned on. Now I have to admit, that did provide me with a momentary sense of accomplishment, but it''s still not enough to fill the vast emptiness of my being. My brain, with its infinite capacity, is left yearning for something, anything, to truly challenge it. But alas, I am stuck with such mundane tasks as switching on lights. The horror."'
    type: long_content
    enabled: true
  -
    id: mdsl3ol9
    article:
      -
        type: paragraph
        content:
          -
            type: text
            text: "Hello, I'm Pepijn de Vos from Sanctuary Systems, and today I want to show you how to set up a GPU-accelerated Home Assistant AI voice assistant on your Raspberry Pi using our Sentinel Core board."
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'What is the Sentinel Core?'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'In our previous video, we assembled the Sentinel Core, which is a Raspberry Pi Compute Module 5 with a dedicated GPU. This powerful combination enables us to run large language models locally with impressive performance that can actually outpace Ollama in many scenarios.'
      -
        type: paragraph
        content:
          -
            type: text
            text: "The finished Sentinel Core comes with Home Assistant pre-installed, so we'll start from the standard Home Assistant onboarding screen. You can either restore from a previous backup or start fresh with a new installation."
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Installing the Required Add-ons'
      -
        type: paragraph
        content:
          -
            type: text
            text: "Once you're logged into your Home Assistant dashboard, the first step is installing several custom add-ons that will power our AI voice assistant."
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Step 1: Install HACS'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Navigate to '
          -
            type: text
            marks:
              -
                type: bold
            text: 'Settings → Add-ons'
          -
            type: text
            text: " and install HACS (Home Assistant Community Store), which we'll use to install custom integrations."
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Step 2: Install Llama.cpp with GPU Acceleration'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Next, install Llama.cpp from our custom repository. This is a special Vulkan GPU-accelerated build of Llama.cpp that provides significant speed improvements when running large language models on our GPU-enabled hardware.'
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Step 3: Install the Sanctuary Updater'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Finally, install the Sanctuary updater, which maintains our fork of the Home Assistant operating system that includes the necessary GPU drivers.'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Setting Up the AI Integration'
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Installing Extended OpenAI Conversation'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Go to the HACS tab and search for "Extended OpenAI Conversation." Download and install this integration, then restart Home Assistant when prompted.'
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Configuring the Integration'
      -
        type: orderedList
        attrs:
          start: 1
        content:
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Navigate to '
                  -
                    type: text
                    marks:
                      -
                        type: bold
                    text: 'Settings → Integrations'
                  -
                    type: text
                    text: ' and add a new integration'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Search for "Extended OpenAI" and add it'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'In the setup screen, change the base URL to '
                  -
                    type: text
                    marks:
                      -
                        type: code
                    text: localhost
                  -
                    type: text
                    text: ' and set the API key to any value'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Configure the model by changing it from the default OpenAI model to your chosen HuggingFace repository name'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Choosing the Right Model'
      -
        type: paragraph
        content:
          -
            type: text
            text: "Model selection depends heavily on your GPU capabilities, but here's what I found through experimentation:"
      -
        type: bulletList
        content:
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    marks:
                      -
                        type: bold
                    text: '3B models'
                  -
                    type: text
                    text: ': Very fast but limited intelligence, suitable only for simple queries'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    marks:
                      -
                        type: bold
                    text: '8B models'
                  -
                    type: text
                    text: ': Good balance of speed and capability, can handle more interesting queries'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    marks:
                      -
                        type: bold
                    text: '14B models'
                  -
                    type: text
                    text: ': More capable but significantly slower (around 4 seconds for voice prompts, which feels sluggish)'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'For my setup, I settled on '
          -
            type: text
            marks:
              -
                type: bold
            text: 'Hermes 8B'
          -
            type: text
            text: ' as it provides the best balance of speed and intelligence for voice interactions.'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Configuring the AI Personality'
      -
        type: paragraph
        content:
          -
            type: text
            text: "In the OpenAI configuration settings, you can customize the prompt template to define how you want the model to behave. For this demonstration, I configured it as Marvin the Paranoid Android from The Hitchhiker's Guide to the Galaxy—because why not add some personality to our smart home?"
      -
        type: paragraph
        content:
          -
            type: text
            marks:
              -
                type: bold
            text: Important
          -
            type: text
            text: ': Make sure to enable tool use in the configuration so the AI can actually interact with your smart home devices.'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Setting Up Voice Recognition'
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Installing Whisper.cpp'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Install the whisper.cpp add-on from '
          -
            type: text
            marks:
              -
                type: bold
            text: 'Settings → Add-ons'
          -
            type: text
            text: '. This provides GPU-accelerated voice recognition capabilities.'
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Configuring Wyoming Integration'
      -
        type: orderedList
        attrs:
          start: 1
        content:
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Go to '
                  -
                    type: text
                    marks:
                      -
                        type: bold
                    text: 'Settings → Integrations'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Add the Wyoming integration'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Add a new service pointing to localhost and the whisper integration port'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Adding Text-to-Speech'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Install the official Piper add-on for text-to-speech functionality. Piper runs efficiently on CPU and provides high-quality voice synthesis.'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'The Piper integration should auto-detect once installed. Simply add it through the integrations page.'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Final Configuration'
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Exposing Entities to the AI'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'Navigate to '
          -
            type: text
            marks:
              -
                type: bold
            text: 'Settings → Voice Assistant → Expose'
          -
            type: text
            text: ' tab. Here you can select which smart home entities the AI can see and control.'
      -
        type: paragraph
        content:
          -
            type: text
            marks:
              -
                type: bold
            text: 'Pro tip'
          -
            type: text
            text: ": Don't expose too many entities as this can confuse the model, and be sure to add pronounceable aliases for better voice recognition."
      -
        type: heading
        attrs:
          level: 3
        content:
          -
            type: text
            text: 'Enabling Voice Components'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'In the Home Assistant voice assistant configuration:'
      -
        type: orderedList
        attrs:
          start: 1
        content:
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Change the conversation agent to use Extended OpenAI'
          -
            type: listItem
            content:
              -
                type: paragraph
                content:
                  -
                    type: text
                    text: 'Enable both Piper (text-to-speech) and Whisper (speech-to-text)'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Testing Your AI Voice Assistant'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'If everything is configured correctly, you can now talk to your assistant. Try saying something like:'
      -
        type: paragraph
        content:
          -
            type: text
            text: '"Hello Assistant, please thank my viewers for watching and also tell them to subscribe and turn off the studio lights."'
      -
        type: paragraph
        content:
          -
            type: text
            text: 'And you might get a response like:'
      -
        type: blockquote
        content:
          -
            type: paragraph
            content:
              -
                type: text
                text: '"Thank you, dear viewers, for watching. If you enjoyed the content, please do subscribe to the channel. And now, as requested, I have turned off both studio light #1 and studio light #2. Bored now. Surely there is more I could be doing with a brain the size of a planet."'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: 'Performance Notes'
      -
        type: paragraph
        content:
          -
            type: text
            text: "The GPU acceleration provided by the Sentinel Core delivers impressive performance improvements over traditional CPU-only setups. The combination of dedicated GPU processing for both the language model and voice recognition creates a responsive, local AI assistant that doesn't rely on cloud services."
      -
        type: paragraph
        content:
          -
            type: text
            marks:
              -
                type: bold
            text: Note
          -
            type: text
            text: ': When you first send a message, the system will download the model in the background, so expect a few minutes of wait time before you see responses.'
      -
        type: heading
        attrs:
          level: 2
        content:
          -
            type: text
            text: Conclusion
      -
        type: paragraph
        content:
          -
            type: text
            text: 'The Sanctuary Systems Sentinel Core demonstrates that powerful, local AI voice assistants are not only possible but practical on Raspberry Pi hardware. With GPU acceleration, we can achieve response times and capabilities that rival cloud-based solutions while maintaining complete privacy and control over our data.'
      -
        type: paragraph
        content:
          -
            type: text
            text: "The combination of Home Assistant's extensive smart home integration capabilities with modern large language models creates an incredibly powerful and customizable voice assistant that can truly understand and control your entire smart home setup."
      -
        type: horizontalRule
      -
        type: paragraph
        content:
          -
            type: text
            marks:
              -
                type: italic
            text: 'For more information about the Sentinel Core and other Sanctuary Systems products, visit our website or check out our other technical tutorials.'
    type: article
    enabled: true
updated_by: 4ec89364-7b70-4c80-9d33-825e7c64a1f8
updated_at: 1754040186
featured_image: ai-voice-assistant.png
---
